{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"APRStoSQL","text":"<p>Welcome to the Wiki.</p> <p>APRStoSQL is a python script designed to stream APRS data into an Database Server.</p> <p>Database Servers Supported: - SQL Server - MySQL/MariaDB</p> <p>The Script will connect to the APRS-IS backbone, filter the data coming in and stream it to a database for any other uses. </p> <p>There is no processing on the data other then parsing it from the APRS-IS data stream.</p> <p>This script can be run either as a standalone application or in Docker.</p> <p>This software is intended for use by Amateur Radio Operators only.</p>"},{"location":"#contact","title":"Contact","text":"<p>If you have questions, please feel free to reach out to me. You can reach me in one of the following ways:</p> <ul> <li>Discord: Ravendos</li> <li>Mastodon: @n8acl@mastodon.radio</li> <li>E-mail: n8acl@qsl.net</li> </ul> <p>Or open an issue on Github. I will respond to it, and of course you, when I can. Remember, this is a hobby and there are other daily distractors that come first, like work, school and family.</p> <p>If you reach out to me and have an error, please include what error you are getting and what you were doing. I may also ask you to send me certain files to look at. Otherwise just reach out to me :).</p>"},{"location":"#change-log","title":"Change Log","text":"<p>Changes Prior to current year have been moved to the ChangeLog on the wiki.</p> <ul> <li> <p>11/07/2024: Added Database support for MySQL/MariaDB and SQL Server.</p> </li> <li> <p>07/03/2024: Initial Release</p> </li> </ul>"},{"location":"about/","title":"About APRStoSQL","text":""},{"location":"about/#description","title":"Description","text":"<p>APRStoSQL is a python script designed to stream APRS data into an Database Server.</p> <p>Database Servers Supported: - SQL Server - MySQL/MariaDB</p> <p>The Script will connect to the APRS-IS backbone, filter the data coming in and stream it to a database for any other uses. </p> <p>There is no processing on the data other then parsing it from the APRS-IS data stream.</p> <p>This script can be run either as a standalone application or in Docker.</p>"},{"location":"about/#features","title":"Features","text":"<ul> <li>Connects to the APRS-IS</li> <li>Filters the data from the backbone</li> <li>Streams the data to a Database Server</li> </ul>"},{"location":"about/#use-cases","title":"Use Cases","text":"<ul> <li>Get a small historical track of stations using APRS</li> <li>Get a more \"Realtime\" feel for the weather in your area</li> </ul>"},{"location":"about/#history","title":"History","text":"<p>This script was born out of the want to have something I had years ago. Back in the day (2006 or so) I was using UI-Vew32 as my APRS Client in my office at home. It had a plug-in that would allow me to redirect the data from the client to a SQL Server Database. I was then able to use that data to look at weather conditions around the area or to get a track history for my friends.</p> <p>UI-Vew32 stopped being developed, even though there are some who still use it, but I have since moved on to other clients. But for a long time I wanted a way to have that functionality of sending the data to a database again. So I decided it was time to sit down and recreate the functionality as a stand-alone project. Thus APRStoSQL was born.</p> <p>This script does use MS SQL Server as a database system. While this is not an open source RDBMS like MySQL/MariaDB and others, it is something that is available for use as a free RDBMS with the developer edition and can be run on either Windows or Linux or in Docker. AS long as you are not using SQL Server in a production environment or way, the delveoper edition is free. I use SQL Server for work and like to be up on current technologies, so I have it running here in my home lab for other things.</p> <p>However, MySQL/MariaDB support is also available in the script.</p>"},{"location":"changelog/","title":"Change Log","text":""},{"location":"changelog/#no-changes-added-to-this-file-yet","title":"No Changes added to this file yet.","text":""},{"location":"configuration_guide/","title":"Configuration Guide","text":"<p>This script uses a JSON file to load the configuration information into the script.</p> <p>You will need the <code>config.json</code> from the repo for the script to work properly.</p> <p>However you run the script (standalone or in Docker) this file will need to be loaded with the correct settings. All Settings are required.</p> <p>Edit the <code>config.json</code> in your editor of choice. It should look something like this:</p> <pre><code>{\n\n    \"callsign\": \"&lt;YOUR CALLSIGN HERE&gt;\",\n    \"filter\" :{\n        \"latitude\": \"&lt;YOUR LATITUDE HERE FORMAT XX.X&gt;\",\n        \"longitude\": \"&lt;YOUR LONGITUDE HERE FORMAT XX.X&gt;\",\n        \"range\": \"&lt;RANGE IN MILES ex: 100&gt;\"\n    },\n\n    \"database\": {\n    \"rdbms_type\": \"mssql\",\n    \"credentials\": {\n      \"username\": \"&lt;SQL SERVER USERNAME HERE&gt;\",\n      \"password\": \"&lt;SQL SERVER PASSWORD HERE&gt;\",\n      \"host\": \"&lt;SQL SERVER HOST HERE&gt;\"\n    }\n\n}\n</code></pre> <ul> <li>Callsign: This is your Callsign. Enter it here, replacing <code>&lt;YOUR CALLSIGN HERE&gt;</code>.</li> <li>Filter: This is how we are going to set the filter for the APRS Stream<ul> <li>Latitude: this is your latitude in XX.X format. Ex: 84.1. Replace <code>&lt;YOUR LATITUDE HERE FORMAT XX.X&gt;</code></li> <li>Longitiude: Same as latitude, but only your longitude instead. Ex: -84.1. Replace <code>&lt;YOUR LONGITUDE HERE FORMAT XX.X&gt;</code></li> <li>Range: This is the range in Miles you want to filter the data from the coordinates you set above. NOTE: There is not an option for all data coming in because that would be way to much data to handle. Replace <code>&lt;RANGE IN MILES ex: 100&gt;</code></li> </ul> </li> <li>database: This is connection info for your Database Server instance. <ul> <li>NOTE: It is not recommended you use a System Administrator account for access. Setup a user that has the ability to at least create databases, tables and has the ability to insert data into tables. </li> <li>rdbms_type: This is the type of database you are using. Options are:<ul> <li>mssql - SQL Server</li> <li>mysql - MySQL/MariaDB Server</li> </ul> </li> <li>credentials: This is where you set the connection credentials<ul> <li>host: This is the host information for your SQL Server instance. This can be an IP Address or FQDN. Ex's: 10.0.0.25 or mydatabase.local Replace <code>&lt;SQL SERVER HOST HERE&gt;</code></li> <li>username: This is the username the script will use to connect to your database instance. Ex: myuser. Replace <code>&lt;SQL SERVER USERNAME HERE&gt;</code></li> <li>password: This is the password for the username above to connect to your database instance. Ex: mypassword. Replace <code>&lt;SQL SERVER PASSWORD HERE&gt;</code></li> </ul> </li> </ul> </li> </ul> <p>Once the information has been entered, save the file and close your editor.</p>"},{"location":"database_datamanagement/","title":"Managing the APRS Data","text":"<p>This project was not created with the intent to create a backup of all APRS data over time. Even though we are filtering the APRS data from the stream, this still loads a ton of data over said period of time. You will need to manage the data otherwise the database will bloat and become huge. </p> <p>Using the queries below, you can create a stored procedure that will delete the data based on a time frame.</p> <pre><code>------------------------------------------\n-- Clean up APRS Database tables\n-- Deletes data 2 weeks old from today\n\ndelete from aprs.dbo.pos\nwhere time_in &lt;= dateadd(d, -14, getdate())\n\ndelete from aprs.dbo.wx\nwhere time_in &lt;= dateadd(d, -14, getdate())\n</code></pre> <p>These queries delete any data that is 2 weeks old from today from my database. Anything over that is too stale for me to use. This helps keep the database managable. Your mileage my vary though and you might want a longer time frame for farther analysis of the data if needed.</p> <p>I have these in a stored procedure with other data table cleanup functions and have a job setup to run my data cleanup daily. </p>"},{"location":"database_description/","title":"Database Description","text":"<p>This is a list of all the objects that are created by the script in your database for reference.</p> <ul> <li>Database Name: APRS</li> </ul> <p>Tables:</p> <p>pos - This holds the postion data from the stream</p> <pre><code>    pos_id int identity(1,1) primary key not null, \n    callsign varchar(20) null,\n    ssid int null,\n    lat decimal(18,2) null,\n    lon decimal (18,2) null,\n    course int default(0),\n    speed int default(0),\n    altitude_ft int default(0),\n    comment varchar(max) null,\n    raw_data varchar(max) null,\n    time_in datetime2 default(getdate())\n</code></pre> <p>wx - This holds the weather data from the stream</p> <pre><code>    wx_id int identity(1,1) primary key not null,\n    callsign varchar(20) null,\n    ssid int null,\n    tempC float null,\n    tempf as 9.0/5.0 * tempC + 32,\n    pressure float null,\n    wind_gust float null,\n    wind_speed float null,\n    wind_direction float null,\n    rain_1h float null,\n    rain_24h float null,\n    rain_since_midnight float null,\n    humidity float null,\n    luminosity float null,\n    raw_data varchar(max),\n    time_in datetime2 default(getdate())\n</code></pre>"},{"location":"database_queries/","title":"Helpful Queries","text":"<p>Here are some example queries that you can use to query the data from the database when needed.</p> <p>These are written for SQL Server, so if you use MySQL, you will have to modify them to work properly.</p> <p>These are all the queries talked about through out this Wiki all in one place.</p>"},{"location":"database_queries/#view-the-data","title":"View the data","text":"<p>Mentioned in the Standalone/Docker documents.</p> <pre><code>use APRS\ngo\n\nselect \n    *\nfrom pos\norder by time_in desc\n\nselect\n    *\nfrom wx\norder by time_in desc\n</code></pre>"},{"location":"database_queries/#clean-up-the-data","title":"Clean up the Data","text":"<p>Mentioned in the Data Management documents.</p> <pre><code>------------------------------------------\n-- Clean up APRS Database tables\n-- Deletes data 2 weeks old from today\n\ndelete from aprs.dbo.pos\nwhere time_in &lt;= dateadd(d, -14, getdate())\n\ndelete from aprs.dbo.wx\nwhere time_in &lt;= dateadd(d, -14, getdate())\n</code></pre>"},{"location":"installation_docker/","title":"Docker","text":"<p>This application can be run in Docker and the image built in one of two ways. Running it in Docker is the recommended way to run the application.</p> <p>The following uses docker compose to bring up the container. If you don't want to use docker compose or are using some other container manager, you will need to configure it yourself. Some of the inststructions below will be useful still though.</p> <p>All commands are for Linux. If you run Docker a different way, you will need to adjust for that as well.</p>"},{"location":"installation_docker/#set-configurations","title":"Set Configurations","text":"<p>You can build the container image locally or pull it from Docker Hub. Either way you need to take some steps first.</p> <p>First, clone the repo:</p> <pre><code>git clone https://github.com/n8acl/aprstosql.git\n</code></pre> <p>Next, follow the instructions in the Configuration Guide (See menu to the left) to setup the config file and then come back here.</p> <p>There is a sample <code>docker-compose.yaml</code> file in the repository that you can edit. Open the <code>docker-compose.yaml</code> and find the <code>volumes</code> section.</p> <p>Make sure to set the path to where your config file is located by changing the <code>&lt;path to your folder&gt;</code> tag.</p> <pre><code>volumes:\n  - /&lt;path to your folder&gt;/aprstosql/config.json:/app/config.json\n</code></pre>"},{"location":"installation_docker/#building-the-image-from-repo","title":"Building the Image from Repo","text":"<p>Once the configuration file has been set and the <code>docker-compose.yaml</code> file has been edited, you can build the image using the following command:</p> <pre><code>docker compose build\n</code></pre> <p>After the the image has been built, bring up the container:</p> <p>Depending on the version of docker compose you are using:</p> <pre><code>docker compose up -d\n</code></pre> <p>- OR -</p> <pre><code>docker-compose up -d\n</code></pre>"},{"location":"installation_docker/#using-image-from-docker-hub-coming-soon","title":"Using Image from Docker Hub (Coming Soon)","text":"<p>If you don't want to build the image yourself, the container can be pulled from the Docker Hub. The container is built with multiarch support and can be run on an x86 machine or a Raspberry Pi.</p> <p>Follow the Configuration Guide above in the section called <code>Set Configurations</code> to set the config file and then come back here.</p> <p>Next, edit the <code>docker-compose.yaml</code> file and change the following:</p> <ul> <li>Find the line that says <code>build: .</code></li> <li>Change this to <code>image: n8acl/aprstosql:latest</code></li> </ul> <pre><code>build: .\n</code></pre> <ul> <li>Find the volumes section.</li> <li>Make sure to set the path to your configuration file by changing the <code>&lt;path to your folder&gt;</code> tag.</li> </ul> <pre><code>volumes:\n  - /&lt;path to your folder&gt;/aprstosql/config.json:/app/config.json\n</code></pre> <p>Save the file.</p> <p>Now pull the image:</p> <p>Depending on the version of docker compose you are using:</p> <pre><code>docker compose pull\n</code></pre> <p>- OR -</p> <pre><code>docker-compose pull\n</code></pre> <p>Once it is pulled, bring it up:</p> <p>Depending on the version of docker compose you are using:</p> <pre><code>docker compose up -d\n</code></pre> <p>- OR -</p> <pre><code>docker-compose up -d\n</code></pre>"},{"location":"installation_docker/#verify-the-data","title":"Verify the Data","text":"<p>Once the container is running, you should be able to see a new database called APRS in SQL Server along with the tables and procedures needed. To verify that data is flowing in to the database, open either SQL Server Management Studio or Azure Data Studio and run the following commands in a new query.</p> <pre><code>use APRS\ngo\n\nselect\n    *\nfrom pos\norder by time_in desc\n\nselect\n    *\nfrom wx\norder by time_in desc\n</code></pre> <p>These should return result grids with the data in the tables and when you re-execute the queries you should see the data update over time.</p> <p>Once the database has been created, you can stop the container and bring it back up at will as needed. If you drop the APRS database from SQL Server at any point, when you run the container again, it will recreate the database.</p>"},{"location":"installation_standalone/","title":"Standalone Application","text":"<p>When running this as a standalone application (Meaning you are running from the command line with Python directly) you will need to take some steps to make sure things are installed.</p>"},{"location":"installation_standalone/#cloning-the-repo","title":"Cloning the repo","text":"<p>First you will need to clone the repo, please run the following command:</p> <pre><code>git clone https://github.com/n8acl/aprstosql.git\n</code></pre>"},{"location":"installation_standalone/#installing-dependencies","title":"Installing Dependencies","text":"<p>Next you will need to make sure that the needed software and python libraries are installed. Please run the following commands to make sure:</p> <pre><code>sudo apt-get install -y python3 python3-pip screen\n\ncd aprstosql\n\npip3 install -r requirements.txt --break-system-packages\n</code></pre>"},{"location":"installation_standalone/#setting-configuration-file","title":"Setting Configuration File","text":"<p>Once you have the repo cloned and the software/python libraries installed, you will need to set the configuration file.</p> <p>Please see the Configuration File documentation for more information and then come back here. (See menu to the left side for the link)</p>"},{"location":"installation_standalone/#running-the-script","title":"Running the Script","text":"<p>Once the config file is setup, you can now run the script. To do so, run the following commands, first making sure that you are in the aprstosql directory:</p> <pre><code>cd aprstosql\n\nscreen -R aprstosql\n\npython3 aprstosql.py\n</code></pre>"},{"location":"installation_standalone/#verify-the-data","title":"Verify the Data","text":"<p>Once the script is running, you should be able to see a new database called APRS in SQL Server along with the tables and procedures needed. To verify that data is flowing in to the database, open either SQL Server Management Studio or Azure Data Studio and run the following commands in a new query.</p> <pre><code>use APRS\ngo\n\nselect \n    *\nfrom pos\norder by time_in desc\n\nselect\n    *\nfrom wx\norder by time_in desc\n</code></pre> <p>These should return result grids with the data in the tables and when you re-execute the queries you should see the data update over time.</p> <p>Once the database has been created, you can stop the container and bring it back up at will as needed. If you drop the APRS database from SQL Server at any point, when you run the script again, it will recreate the database. </p> <p>You should be good to go. Close out of screen to leave the script running:</p> <p><code>Ctrl-A-D</code></p> <p>If there is an error or you need to restart the script for some reason, you can reconnect to the screen session by using:</p> <pre><code>screen -R aprstosql\n</code></pre>"}]}